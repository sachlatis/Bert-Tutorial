{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "introduction-to-bert.ipynb",
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6243d5a1817e4b28a61ceecc4a0a4ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a179ee0977c94246b8b4a17e73fc1f6b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bf6fd5c16c10456098b71d35df8ab3b4",
              "IPY_MODEL_805838c7a6aa47cb8174890d0638d736",
              "IPY_MODEL_7237c4426eba46c1a3e089201781c6e6"
            ]
          }
        },
        "a179ee0977c94246b8b4a17e73fc1f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf6fd5c16c10456098b71d35df8ab3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0cfa569401e445b989cf06d69f044036",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7466178f9d0f4caeb40ba2d7a93b5c94"
          }
        },
        "805838c7a6aa47cb8174890d0638d736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_32447385d0974956a711fe5908d5137b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd7c3052d62a4286ab3cf1a22f50727e"
          }
        },
        "7237c4426eba46c1a3e089201781c6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5944179873b84ab4bb492f0128f8648c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.75MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc223bc8a16941afb7c590641a5e54a4"
          }
        },
        "0cfa569401e445b989cf06d69f044036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7466178f9d0f4caeb40ba2d7a93b5c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32447385d0974956a711fe5908d5137b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd7c3052d62a4286ab3cf1a22f50727e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5944179873b84ab4bb492f0128f8648c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc223bc8a16941afb7c590641a5e54a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e589913dd5594f2a808e496cabc7b88d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_93b308c0c8de451b97bfd38446774af3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9c6c9ded137245c0b98b70f06f60d10e",
              "IPY_MODEL_57ad19a9465e435e981b01be5e811684",
              "IPY_MODEL_98d5c2f61bfe4e1cb7e7302c2a520a52"
            ]
          }
        },
        "93b308c0c8de451b97bfd38446774af3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c6c9ded137245c0b98b70f06f60d10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c7ba3073cce42589066f3cf574fea30",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_854c5fa1b327473d86ce3e00e87182d0"
          }
        },
        "57ad19a9465e435e981b01be5e811684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_21918d5be9b248cbb34025de01b6acd4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a639f8cfe32e408ba17a94aa6072bcb9"
          }
        },
        "98d5c2f61bfe4e1cb7e7302c2a520a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c1d431b0b7c448ab90a3826abbbd907f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 644B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1673be7911a24844bc5955f02812accc"
          }
        },
        "3c7ba3073cce42589066f3cf574fea30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "854c5fa1b327473d86ce3e00e87182d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21918d5be9b248cbb34025de01b6acd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a639f8cfe32e408ba17a94aa6072bcb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1d431b0b7c448ab90a3826abbbd907f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1673be7911a24844bc5955f02812accc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "309d8cd779194be5880f4b5c917faedd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48b2bde31695457885bf5e12a1a3e6f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_377216f76932490c98c6176dc3b37fb0",
              "IPY_MODEL_7f2efe4f3a25488a87ca4cfe3787b298",
              "IPY_MODEL_0bfa901e698c4c9c92ec263cea737d64"
            ]
          }
        },
        "48b2bde31695457885bf5e12a1a3e6f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "377216f76932490c98c6176dc3b37fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f834052d1d9942549112bb0b2ce44b09",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20e0a9ce4c5843bead613ee1f3858bd5"
          }
        },
        "7f2efe4f3a25488a87ca4cfe3787b298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a088140b7554b7992944360495f5a66",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e72d9cd7202491ea7e78663b944a8c3"
          }
        },
        "0bfa901e698c4c9c92ec263cea737d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff9bf757c5194037aee7a49f70b92647",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.53MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_883843cde34343fa9eae2e4d8188d306"
          }
        },
        "f834052d1d9942549112bb0b2ce44b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20e0a9ce4c5843bead613ee1f3858bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a088140b7554b7992944360495f5a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e72d9cd7202491ea7e78663b944a8c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff9bf757c5194037aee7a49f70b92647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "883843cde34343fa9eae2e4d8188d306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cc41c7b9df34acb9524bd20790ca7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_09333ba549484057ae457fabaf9de06b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1ffeaed568414dc496637cda39669143",
              "IPY_MODEL_eac3612660fc4aafa9eaee5cfe00dc4a",
              "IPY_MODEL_036064a0184d466dafe255a5af05b232"
            ]
          }
        },
        "09333ba549484057ae457fabaf9de06b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ffeaed568414dc496637cda39669143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_77f42c3abd7e4ded82d45f6bf5d194ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c86aa5db3b046e2918f0451163deadb"
          }
        },
        "eac3612660fc4aafa9eaee5cfe00dc4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b235337f82824a59bb4faa97130cb884",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c37e641c0844460858abab9221de8a5"
          }
        },
        "036064a0184d466dafe255a5af05b232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_febfe978eefb42569f3e3de09193a7c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 13.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e0555957bbd4ff0a961eeab4eb4e5fb"
          }
        },
        "77f42c3abd7e4ded82d45f6bf5d194ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c86aa5db3b046e2918f0451163deadb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b235337f82824a59bb4faa97130cb884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c37e641c0844460858abab9221de8a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "febfe978eefb42569f3e3de09193a7c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e0555957bbd4ff0a961eeab4eb4e5fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0efc7079575e46b6a2da91195b154862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_731e66d3121f4cffb2003db78d1f5ffa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b8be3951cb0a4affa5bbf75362ae8a6f",
              "IPY_MODEL_d2a3ba1d1868491ea37c77ef6a2ef5de",
              "IPY_MODEL_1a468aac230845e28b6b8a3590ed4131"
            ]
          }
        },
        "731e66d3121f4cffb2003db78d1f5ffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8be3951cb0a4affa5bbf75362ae8a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_20bdca5b2c6a4935932f1d24a466d0d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56395f68fa96468ab05d961cc0d888ac"
          }
        },
        "d2a3ba1d1868491ea37c77ef6a2ef5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_29445e8a5222468cb46bdad58424e83d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38568a1b5042497d8cb553a9f5854c1f"
          }
        },
        "1a468aac230845e28b6b8a3590ed4131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b08c33e6ed6c48b59e2157cc95e06eda",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:10&lt;00:00, 35.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0d0fac979694ac383137de915440ca8"
          }
        },
        "20bdca5b2c6a4935932f1d24a466d0d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56395f68fa96468ab05d961cc0d888ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29445e8a5222468cb46bdad58424e83d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38568a1b5042497d8cb553a9f5854c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b08c33e6ed6c48b59e2157cc95e06eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0d0fac979694ac383137de915440ca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCUOKd4LFfw6"
      },
      "source": [
        "# An introduction to inference with BERT\n",
        "\n",
        "This notebook gives an example of how [BERT](https://arxiv.org/abs/1810.04805) can be used to extract\n",
        "sentence embeddings while at the same time giving some information about the model. Note that it does not try\n",
        "to be exhaustive. In some places, links are given as suggestions for further reading. Also note that these days,\n",
        "BERT isn't state of the art anymore. However, the methodology used here can be used in other models such as RoBERTa\n",
        "with minimal changes. Be careful, though, because the differences between model APIs, however small, are incredibly\n",
        "important. For instance, the position of the classification token is not the same for all models. Read the paper,\n",
        "the documentation, or - if you're up for it - the source code! The latter might be a challenge at first, but you \n",
        "learn a lot from it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzrEf62PFzXU",
        "outputId": "9f5ce8fe-ae27-41a3-f81c-fb51a9f9ec71"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 54.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 35.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 39.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.3)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "Ayb66pQcFfw7"
      },
      "source": [
        "import torch\n",
        "from transformers import BertModel, BertTokenizer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHRuCva8Ffw7"
      },
      "source": [
        "## The tokenizer\n",
        "\n",
        "A deep learning model works with tensors. Tensors are (basically) vectors. Vectors are (basically) a bunch of\n",
        "numbers. To get started, then, the input text (string) needs to be converted into some data type (numbers)\n",
        "that the model can use. This is done by the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "6243d5a1817e4b28a61ceecc4a0a4ed7",
            "a179ee0977c94246b8b4a17e73fc1f6b",
            "bf6fd5c16c10456098b71d35df8ab3b4",
            "805838c7a6aa47cb8174890d0638d736",
            "7237c4426eba46c1a3e089201781c6e6",
            "0cfa569401e445b989cf06d69f044036",
            "7466178f9d0f4caeb40ba2d7a93b5c94",
            "32447385d0974956a711fe5908d5137b",
            "bd7c3052d62a4286ab3cf1a22f50727e",
            "5944179873b84ab4bb492f0128f8648c",
            "bc223bc8a16941afb7c590641a5e54a4",
            "e589913dd5594f2a808e496cabc7b88d",
            "93b308c0c8de451b97bfd38446774af3",
            "9c6c9ded137245c0b98b70f06f60d10e",
            "57ad19a9465e435e981b01be5e811684",
            "98d5c2f61bfe4e1cb7e7302c2a520a52",
            "3c7ba3073cce42589066f3cf574fea30",
            "854c5fa1b327473d86ce3e00e87182d0",
            "21918d5be9b248cbb34025de01b6acd4",
            "a639f8cfe32e408ba17a94aa6072bcb9",
            "c1d431b0b7c448ab90a3826abbbd907f",
            "1673be7911a24844bc5955f02812accc",
            "309d8cd779194be5880f4b5c917faedd",
            "48b2bde31695457885bf5e12a1a3e6f4",
            "377216f76932490c98c6176dc3b37fb0",
            "7f2efe4f3a25488a87ca4cfe3787b298",
            "0bfa901e698c4c9c92ec263cea737d64",
            "f834052d1d9942549112bb0b2ce44b09",
            "20e0a9ce4c5843bead613ee1f3858bd5",
            "6a088140b7554b7992944360495f5a66",
            "8e72d9cd7202491ea7e78663b944a8c3",
            "ff9bf757c5194037aee7a49f70b92647",
            "883843cde34343fa9eae2e4d8188d306",
            "9cc41c7b9df34acb9524bd20790ca7d7",
            "09333ba549484057ae457fabaf9de06b",
            "1ffeaed568414dc496637cda39669143",
            "eac3612660fc4aafa9eaee5cfe00dc4a",
            "036064a0184d466dafe255a5af05b232",
            "77f42c3abd7e4ded82d45f6bf5d194ce",
            "2c86aa5db3b046e2918f0451163deadb",
            "b235337f82824a59bb4faa97130cb884",
            "2c37e641c0844460858abab9221de8a5",
            "febfe978eefb42569f3e3de09193a7c4",
            "2e0555957bbd4ff0a961eeab4eb4e5fb"
          ]
        },
        "id": "5W_a-DySFfw7",
        "outputId": "eb1655e1-df80-4471-bec4-bd165097bc64"
      },
      "source": [
        "# Initialize the tokenizer with a pretrained model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6243d5a1817e4b28a61ceecc4a0a4ed7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e589913dd5594f2a808e496cabc7b88d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "309d8cd779194be5880f4b5c917faedd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cc41c7b9df34acb9524bd20790ca7d7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "FyoZULNYFfw8"
      },
      "source": [
        "During pretraining, the tokenizer has been \"trained\" as well. It has generated a vocabulary that it \"knows\". Each word \n",
        "has been assigned an index (a number) and that number can then be used in the model. To counter the annoying problem of \n",
        "words that the tokenizer doesn't know yet (out-of-vocabulary or OOV), a special technique is used that ensures that the\n",
        "tokenizer has learnt \"subword units\". That should mean that when using the pretrained models, you won't run into OOV\n",
        "problems. When the tokenizer does not recognize a word (it is not in its vocabulary) it will try to split that word up \n",
        "into smaller parts that it does know. The BERT tokenizer uses [WordPiece](https://arxiv.org/pdf/1609.08144.pdf)\n",
        "to split tokens. As an example, you'll see that `granola` is split into `gran` and `##ola` where `##` indicates the\n",
        "start of the substring."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POQeIVY4Ffw8",
        "outputId": "440f0490-dde0-4463-ce04-c68b937e72c5"
      },
      "source": [
        "# Convert the string \"granola bars\" to tokenized vocabulary IDs\n",
        "granola_ids = tokenizer.encode('granola bars')\n",
        "# Print the IDs\n",
        "print('granola_ids', granola_ids)\n",
        "print('type of granola_ids', type(granola_ids))\n",
        "# Convert the IDs to the actual vocabulary item\n",
        "# Notice how the subword unit (suffix) starts with \"##\" to indicate \n",
        "# that it is part of the previous string\n",
        "print('granola_tokens', tokenizer.convert_ids_to_tokens(granola_ids))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "granola_ids [101, 12604, 6030, 6963, 102]\n",
            "type of granola_ids <class 'list'>\n",
            "granola_tokens ['[CLS]', 'gran', '##ola', 'bars', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% md\n"
        },
        "id": "Y2nijgcTFfw8"
      },
      "source": [
        "You will probably have noticed the so-called \"special tokens\" [CLS] and [SEP]. These tokens are added automatically by \n",
        "the `.encode()` method so we don't have to worry about them. The first one is a classification token which has been \n",
        "pretrained. It is specifically inserted for any sort of classification task. So instead of having to average of all \n",
        "tokens and use that as a sentence representation, it is recommended to just take the output of the [CLS] which then \n",
        "represents the whole sentence. [SEP], on the other hand, is inserted as a separator between multiple instances. We will\n",
        "not use that here, but it used for things like next sentence prediction where it is a separator between the current and \n",
        "the next sentence. It is especially important to remember the [CLS] token as it can play a great role in classification \n",
        "and regression tasks. \n",
        "\n",
        "We almost have the correct data type to get started. As we saw above, the data type of the token IDs is a list of\n",
        "integers. In this notebook we use the `transformers` library in combination with PyTorch, which works with tensors.\n",
        "A tensor is a special type of optimised list which is typically used in deep learning. To convert our token IDs to a\n",
        "tensor, we can simply put the list in a tensor constructor. Here, we use a `LongTensor` which is used for integers.\n",
        "For floating-point numbers, we'd typically use a `FloatTensor` or just `Tensor`. The `.encode()` method of the \n",
        "tokenizer can return a tensor instead of a list by passing the parameter `return_tensors='pt'` but for illustrative\n",
        "purposes, we will do the conversion from a list to a tensor manually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqMmkF5RFfw9",
        "outputId": "62acae48-b848-43e0-8dcc-d32beba3af82"
      },
      "source": [
        "# Convert the list of IDs to a tensor of IDs \n",
        "granola_ids = torch.LongTensor(granola_ids)\n",
        "# Print the IDs\n",
        "print('granola_ids', granola_ids)\n",
        "print('type of granola_ids', type(granola_ids))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "granola_ids tensor([  101, 12604,  6030,  6963,   102])\n",
            "type of granola_ids <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6R4P3BWhFfw-"
      },
      "source": [
        "## The model\n",
        "Now that we have preprocessed our input string into a tensor of IDs, we can feed this to the model. Remember that the \n",
        "IDs are the IDs of a token in the tokenizer's vocabulary. The model \"knows\" which words are being processed because it\n",
        "\"knows\" which token belongs to which ID. In BERT, and in most - if not all - current transformer language models, the\n",
        "first layer is an embedding layer. Each token ID has a embeddings appointed to it. In BERT, the embeddings are the sum\n",
        "of three types of embeddings: the token embedding, the segment embedding, and the position embedding. The token\n",
        "embedding is a value for the given token, the segment embedding indicates whether the segment is the first or the\n",
        "(optional) second one, and the positional embedding distinguishes the position in the input. Below you find a figure\n",
        "from the BERT paper. (See how playing is split in \"play\" and \"##ing\"?) Note that in our case, where we just use BERT\n",
        "for inference of a single sentence, the segmentation embedding is of no importance. For more information, see\n",
        "[this Medium article](https://medium.com/@_init_/why-bert-has-3-embedding-layers-and-their-implementation-details-9c261108e28a).  We'll come back to the model architecture later on.\n",
        "\n",
        "![BERT embeddings visualization](img/bert-embeddings.png)\n",
        "\n",
        "(For a very detailed and visual explanation of the whole BERT model, have a look at the explanations on\n",
        "[Jay Alammar's homepage](http://jalammar.github.io/). In particular the \"Illustrated transformer\" is very interesting.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhB9FPpOFfw_"
      },
      "source": [
        "To get started, we first need to initialize the model. Just like the tokenizer, the model is pretrained which makes it\n",
        "very easy for us to just use the pretrained language model to get some token or sentence representations out of it.\n",
        "Note how we use the same pretrained model as the tokenizer uses (`bert-base-uncased`). This is the smaller BERT model\n",
        "that has been trained on lower case text. Because the model has been trained on lower case text, it does not know cased\n",
        "text. You may hav enoticed that the tokenizer automatically lowercases the text for us. Whether to use a cased or\n",
        "uncased language model really depends on the task. If you think that casing matters (e.g. for NER), you may want to\n",
        "opt for a cased model, otherwise casing might just add noise.\n",
        "\n",
        "In the example below, an additional argument has been given to the model initialisation. `output_hidden_states` will\n",
        "give us more output information. By default, a `BertModel` will return a tuple but the contents of that tuple differ\n",
        "depending on the configuration of the model. When passing `output_hidden_states=True`, the tuple will contain\n",
        "(in order; shape in brackets):\n",
        "\n",
        "1. the last hidden state `(batch_size, sequence_length, hidden_size)`\n",
        "2. the pooler_output of the classification token `(batch_size, hidden_size)`\n",
        "3. the hidden_states of the outputs of the model at each layer and the initial embedding outputs\n",
        "   `(batch_size, sequence_length, hidden_size)`\n",
        "\n",
        "Graphic cards (GPUs) are much better at doing operations on tensors than a CPU is. Therefore, we wish to run our \n",
        "computations on the GPU if it is available. Note that you need to have a GPU available as well as CUDA, and a\n",
        "GPU-accelerated torch version. To increase the calculation speed, we have to move our model to the correct device:\n",
        "if it's available we'll move the model `.to()` the GPU, otherwise it'll stay on the CPU. It is important to remember \n",
        "that the model and the data to process need to be on the same device. This means that we will have to move our \n",
        "`granola_ids` to the same device as the model, too.\n",
        "\n",
        "Finally, we also set the model to evaluation mode (`.eval`) in contrast to training mode (`.train()`). In evluation\n",
        "mode, the model's batchnorm and dropout layers will work in `eval()` mode, e.g. disabling dropout, which you only want\n",
        "during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0efc7079575e46b6a2da91195b154862",
            "731e66d3121f4cffb2003db78d1f5ffa",
            "b8be3951cb0a4affa5bbf75362ae8a6f",
            "d2a3ba1d1868491ea37c77ef6a2ef5de",
            "1a468aac230845e28b6b8a3590ed4131",
            "20bdca5b2c6a4935932f1d24a466d0d0",
            "56395f68fa96468ab05d961cc0d888ac",
            "29445e8a5222468cb46bdad58424e83d",
            "38568a1b5042497d8cb553a9f5854c1f",
            "b08c33e6ed6c48b59e2157cc95e06eda",
            "e0d0fac979694ac383137de915440ca8"
          ]
        },
        "id": "dOYVwToJFfxA",
        "outputId": "b0aaf0ea-4e50-4abd-cada-e094a8f6f380"
      },
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "# Set the device to GPU (cuda) if available, otherwise stick with CPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = model.to(device)\n",
        "granola_ids = granola_ids.to(device)\n",
        "\n",
        "model.eval()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0efc7079575e46b6a2da91195b154862",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1XHsvunlFfxA"
      },
      "source": [
        "## Inference\n",
        "The model has been initialized, and the input string has been converted into a tensor. A language model (such as \n",
        "`BertModel` above) has a `forward()` method that is called automatically when calling the object. The forward method \n",
        "basically pushes a given input tensor forward through the model and then returns the output. Since we're only doing\n",
        "inference and not training or fine-tuning the model, this is the only step that involves the model directly to get \n",
        "output. So we don't need to optimize the model (calculate gradients, propagating back). That's quite simple, isn't it?\n",
        "One pecularity is that we set `torch.no_grad()`. This tells the model that we won't be doing any gradient \n",
        "calculation/backpropagation. Ultimately, it makes inference faster and more memory-efficient. You would typically use\n",
        "`model.eval()` (see above) and `torch.no_grad()` together for evaluation and testing of your model. When training the\n",
        "model should be set to `model.train()` and `torch.no_grad()` should *not* be used.\n",
        "\n",
        "In the cell below, you'll see that there's a strange method called `.unsqueeze()`. It \"unsqueezes\" a tensor by adding \n",
        "an extra dimension. In our case, you'll see that our granola tensor of size `(5,)` turns into a different shape of\n",
        "`(1, 5)` where `1` is the dimension of the sentence. These two dimensions are required by the model: it is optimised\n",
        "to train on *batches*. The next paragraph goes into a bit more technical detail but is not required to understand this \n",
        "notebook.\n",
        "\n",
        "A batch consists of multiple input texts at \"the same time\" (typically of the power of two, e.g. 64). With a batch size\n",
        "of 64 (64 sentences at once), the batch size would be `(64, n)` where `64` is the number of sentences, and `n` the\n",
        "sequence length. In this notebook, where we only ever use one input, the following is not important, but if you ever\n",
        "want to fine-tune a model, you'll want to work with batches since the gradient calculation will be better for large\n",
        "batches. In such cases, `n` needs to be the same for all entries; you cannot have one sequence of 5 items and one of\n",
        "12 items. That is where padding comes in - but that is a story for another day. For now, you can remember that the\n",
        "input size of the model needs to be `(n_input_sentences, seq_len)` where `seq_len` can be determined in different ways.\n",
        "Two popular choices are: using the longest text in the batch as `seq_len` (e.g. 12) and padding shorter texts up to\n",
        "this length, or setting a fixed maximal sequence length for the model (typically 512) and pad all items up to this\n",
        "length. The latter approach is easier to implement but is not memory-efficient and is computationally heavier. The\n",
        "choice, as always, is yours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLammsvBFfxB",
        "outputId": "9dee91cb-97cb-4ef9-eab2-c4b9d0fdf9da"
      },
      "source": [
        "print(granola_ids.size())\n",
        "# unsqueeze IDs to get batch size of 1 as added dimension\n",
        "granola_ids = granola_ids.unsqueeze(0)\n",
        "print(granola_ids.size())\n",
        "\n",
        "print(type(granola_ids))\n",
        "with torch.no_grad():\n",
        "    out = model(input_ids=granola_ids)\n",
        "\n",
        "# the output is a tuple\n",
        "print(type(out))\n",
        "# the tuple contains three elements as explained above)\n",
        "print(len(out))\n",
        "# we only want the hidden_states\n",
        "hidden_states = out[2]\n",
        "print(len(hidden_states))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5])\n",
            "torch.Size([1, 5])\n",
            "<class 'torch.Tensor'>\n",
            "<class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'>\n",
            "3\n",
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% md\n"
        },
        "id": "IvYpnLcWFfxB"
      },
      "source": [
        "As discussed above, we push the IDs of our input tokens through the `model()`, which internally calls the model's \n",
        "`forward()` method. `out` is a tuple with all relevant output items (see the list that we discussed earlier on). For us\n",
        "the third item in that tuple is the most important one; it contains all `hidden_states` of the model after a forward\n",
        "pass. `hidden_states` is a tuple of the output of each layer in the model for each token. In the previous\n",
        "cell we saw that the tuple contains 13 items. When you execute the cell below, the architecture of the BertModel is\n",
        "shown (from top-down to the bottom). The `hidden_states` include the output of the `embeddings` layer and the output of\n",
        "all 12 `BertLayer`'s in the encoder. The output of each layer has a size of `(batch_size, sequence_length, 768)`.\n",
        "In our case, that is `(1, 5, 768)` because we only have one input string (batch size of 1), and our input string was\n",
        "tokenized into five IDs (sequence length of 5). `768` is the number of hidden dimensions.\n",
        "\n",
        "The critical reader will notice that there is still one more layer after the encoder, called `pooler`, which is not\n",
        "part of `hidden_states`. This layer is used to \"pool\" the output of the classification token but we will not use that \n",
        "here. Its output is returned in the second item of the output tuple `out`, as discussed before.\n",
        "\n",
        "For an in-depth analysis of BERT's architecture, I'd \n",
        "recommend to read [the paper](https://arxiv.org/abs/1810.04805). However, if you like a more visual explanation, \n",
        "[The Illustrated BERT](http://jalammar.github.io/illustrated-bert/) might be a better place to start."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% \n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_Uh7ZdeFfxC",
        "outputId": "9671bdcf-6e26-4f21-b294-09e73d98dc0f"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "P8ko7AL5FfxC"
      },
      "source": [
        "Now that we have all hidden_states, we may want to get a usable value out of it. Let's say that we want to retrieve a\n",
        "sentence embedding by averaging over all tokens. In other words, we want to reduce the size of `(1, 5, 768)` to\n",
        "`(1, 768)` where `1` is the batch size and `768` is the number of hidden dimensions. (One could also call `768` the \n",
        "features that you wish to use in another task.) There are many ways to make a sentence abstraction of tokens, and it \n",
        "often depends on the given task. Here, we will take the mean. For now, we will only use the output of the last layer in\n",
        "the encoder, that is, `hidden_states[-1]`. It is important to indicate that we want to take the `torch.mean`\n",
        "_over a given axis_. Since the size of the output of the layers is `(1, 5, 768)`, we want to average over the five \n",
        "tokens, which are in the second dimension (`dim=1`). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25sDHkLwFfxD",
        "outputId": "f40fe96e-0792-42bc-a4a3-a1851ee1f124"
      },
      "source": [
        "sentence_embedding = torch.mean(hidden_states[-1], dim=1).squeeze()\n",
        "print(sentence_embedding)\n",
        "print(sentence_embedding.size())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 2.7497e-01,  1.8313e-01, -8.8652e-02,  2.1698e-01,  3.1942e-01,\n",
            "        -1.1412e-01,  7.4039e-02,  3.7655e-01, -4.1821e-01,  9.9971e-02,\n",
            "        -9.0242e-02, -2.4298e-01,  1.5542e-01,  4.2042e-01, -2.5547e-01,\n",
            "         2.9753e-01, -2.9643e-01, -2.5810e-02,  8.5306e-02,  1.0182e-01,\n",
            "         3.0401e-01, -4.4263e-01,  3.1249e-02,  1.4435e-01,  3.0189e-01,\n",
            "         7.3914e-02, -2.5580e-01,  3.1384e-01, -1.4688e-01, -1.5202e-01,\n",
            "         7.0785e-02,  4.0448e-01, -1.1769e-01,  3.1848e-01,  2.8022e-02,\n",
            "        -1.6934e-01,  3.5639e-01, -2.2931e-01, -1.1899e-01, -1.1182e-01,\n",
            "        -1.6003e-01,  7.9355e-02,  5.1107e-01,  5.2223e-02, -1.5481e-01,\n",
            "         2.8228e-02, -1.4365e-01, -4.7737e-01, -5.6638e-01, -4.8802e-01,\n",
            "        -1.1429e-01,  2.8087e-01, -5.7160e-02,  2.3862e-01,  3.5440e-01,\n",
            "         5.8237e-01,  1.2777e-01,  1.0363e-01,  3.0538e-01,  2.0989e-01,\n",
            "         1.1693e-01,  2.6346e-01, -1.5832e-01, -1.1380e-01,  1.7190e-02,\n",
            "        -3.4662e-02,  1.1470e-01,  3.2023e-02, -1.9781e-01, -1.2561e-01,\n",
            "        -4.8289e-02, -2.4562e-01,  5.0645e-03, -2.4147e-02,  2.2932e-01,\n",
            "        -1.9112e-01, -4.4624e-01,  8.6932e-02, -6.9348e-02, -2.6828e-01,\n",
            "         3.0473e-01,  3.3020e-01,  1.4786e-01,  3.7107e-01, -7.5337e-02,\n",
            "         3.3730e-01, -2.6694e-01, -1.1731e-01,  7.5014e-02,  4.6462e-01,\n",
            "        -1.4554e-01,  2.2035e-02,  3.7995e-01,  3.0877e-01,  3.8794e-01,\n",
            "        -5.0270e-02, -8.4905e-02, -1.6390e-01,  5.2378e-01,  1.8881e-01,\n",
            "         2.1467e-02, -8.5598e-02,  2.4094e-01,  3.2501e-01, -2.4542e-01,\n",
            "        -2.2705e-01, -2.5746e-01,  2.9763e-01, -1.7600e-02, -8.6889e-01,\n",
            "         1.7624e-01,  2.9194e-02,  7.0749e-02, -2.1513e-01, -3.4476e-01,\n",
            "        -1.7142e-01,  3.5134e-01,  3.5487e-01, -1.6037e-01,  2.3332e-01,\n",
            "        -1.6640e-01,  1.5522e-02, -1.3603e-01,  9.8263e-01, -1.6572e-01,\n",
            "         8.6756e-02,  1.7275e-02,  3.1124e-02,  4.5488e-01,  9.1418e-02,\n",
            "        -1.2291e-01,  2.6948e-01,  7.5361e-02,  8.1167e-02, -2.8039e-01,\n",
            "         8.6070e-02,  2.8712e-01, -3.2012e-01, -1.0920e-01, -3.4677e-01,\n",
            "        -2.3220e-01,  1.7452e-01, -8.9247e-01, -3.8039e-01,  1.6933e-01,\n",
            "        -4.0088e-02,  7.6205e-02,  2.0971e-01,  4.3188e-01, -5.6367e-02,\n",
            "         4.2553e-01,  6.6853e-02, -4.0933e-01,  2.4338e-01, -9.9158e-02,\n",
            "        -1.1955e-01, -3.4792e-01, -7.9455e-02,  2.1929e-01,  3.0778e-01,\n",
            "         3.1282e-01,  8.8517e-02,  1.4369e-01,  1.2767e-02, -2.3661e-01,\n",
            "        -2.5115e-01, -1.8090e-02,  9.1526e-02,  2.6671e-03,  3.7868e-01,\n",
            "        -1.7585e-01, -1.7576e-01,  4.4584e-01, -3.5462e-01, -3.4920e-01,\n",
            "         4.2924e-02,  1.1444e-02,  5.6267e-01,  5.9517e-03,  4.5876e-02,\n",
            "        -1.8924e+00,  6.9178e-02,  4.4243e-01, -1.2979e-02,  3.2357e-01,\n",
            "        -5.8837e-03,  5.9261e-01, -6.0558e-01,  1.8617e-01, -3.9271e-01,\n",
            "         2.7042e-01, -3.7876e-01, -2.2174e-01,  1.2152e-01,  3.6275e-01,\n",
            "        -1.9326e-01,  6.0437e-02, -3.5042e-01,  1.2261e-01, -4.3831e-02,\n",
            "        -1.9312e-01,  1.5187e-01,  1.3780e-01, -9.7899e-02, -3.7317e-01,\n",
            "         1.2430e+00,  3.2932e-01, -1.9085e-01,  2.1563e-01, -1.0158e-01,\n",
            "        -1.9931e-01,  4.1641e-01,  7.6540e-02, -2.9979e-01, -6.5521e-03,\n",
            "        -7.7947e-02,  4.2823e-03, -5.3286e-02, -2.8932e-01, -3.4238e-01,\n",
            "         2.9741e-01, -7.0199e-02, -4.5928e-01,  2.9630e-01, -2.5724e-01,\n",
            "        -1.6242e-01, -8.9294e-02,  1.3588e-01,  1.9840e-01,  7.3456e-02,\n",
            "         2.5921e-01,  1.7004e-01,  1.0998e-01,  2.1080e-01, -3.7167e-01,\n",
            "         8.9602e-02, -2.4095e-02,  3.9413e-02,  9.6415e-02, -3.9217e-01,\n",
            "        -1.8365e-01,  1.1395e-01,  4.8770e-01,  1.1218e-03, -1.9569e-01,\n",
            "        -1.2228e-02,  3.1669e-01,  2.1529e-01,  2.5503e-01, -2.3742e-01,\n",
            "         3.5058e-02, -8.1064e-01,  2.4611e-03, -2.6651e-01,  4.3942e-01,\n",
            "         1.9389e-02,  6.3593e-02, -2.3803e-01,  9.2669e-02,  1.8258e-01,\n",
            "        -3.8495e-02,  2.3593e-01,  5.7420e-01, -2.0413e-01, -4.4064e-01,\n",
            "         5.3445e-02, -1.5976e-01,  1.8722e-02, -1.0571e-01,  1.6751e-01,\n",
            "        -5.6544e-02,  3.5808e-02, -1.6339e-01, -1.2839e+00, -1.0260e-01,\n",
            "        -6.7205e-02,  1.2519e-01,  9.1995e-02, -4.3033e-02, -7.7113e-02,\n",
            "        -1.9279e-01,  4.8786e-01, -4.6132e-02,  2.3583e-01, -5.8109e-01,\n",
            "        -3.5453e-01, -1.2584e-01, -1.9348e-01, -1.5997e-02,  8.0766e-02,\n",
            "         7.3319e-03,  3.1523e-01, -4.2058e-01, -2.6260e-01, -2.7528e-02,\n",
            "        -1.1586e-01,  5.3806e-03,  4.3207e-01,  2.3536e-01, -5.6140e-01,\n",
            "        -9.4499e-02, -1.6396e-01,  1.5114e-01,  2.6866e-01, -5.2128e-02,\n",
            "         2.1231e-01, -1.9071e-02, -3.1587e-01, -3.1075e+00, -9.8635e-02,\n",
            "        -2.5031e-01, -4.1425e-01,  2.7539e-01, -5.0086e-01, -1.8764e-01,\n",
            "        -1.1095e-01, -3.1184e-01, -1.1116e-01, -3.4540e-01, -2.2962e-01,\n",
            "         2.4196e-01,  2.2008e-01,  2.9891e-01, -1.4837e-01,  2.3513e-01,\n",
            "        -1.4459e-01, -7.1072e-02,  3.1104e-01,  8.4301e-02, -4.1443e-01,\n",
            "         1.9445e-01, -1.7383e-01,  1.0017e-01,  3.1795e-01, -2.7422e-01,\n",
            "         3.4965e-01, -4.7570e-01, -1.1109e-01, -4.1904e-01,  1.8018e-01,\n",
            "        -3.4424e-01, -4.1224e-01,  3.8817e-01,  5.1788e-02, -5.0654e-01,\n",
            "         1.2701e-01,  5.8633e-01, -7.6471e-02,  1.5943e-01,  4.0271e-01,\n",
            "        -1.7491e-01,  8.8953e-02,  4.1438e-01,  7.0470e-02, -2.2776e-01,\n",
            "        -5.2665e-01, -4.8418e-02,  4.7993e-01,  2.6683e-01,  5.4173e-02,\n",
            "         3.4134e-01, -2.9446e-02,  2.8612e-01, -1.2683e-01,  3.2365e-01,\n",
            "         1.5207e-02,  7.5879e-02, -2.1957e-01,  4.3722e-01, -1.9480e-01,\n",
            "        -1.4549e-01,  2.1158e-01, -1.9193e-01,  8.2931e-02, -2.9274e-01,\n",
            "        -3.1519e-02,  8.2016e-02,  1.0614e-02, -2.1728e-01, -2.4810e-01,\n",
            "         8.3924e-02, -9.3397e-01,  9.7814e-02, -8.4303e-02, -1.4857e-01,\n",
            "        -5.1369e-02,  3.3001e-01,  1.8646e-01,  1.0419e-01, -2.0374e-01,\n",
            "        -3.7991e-02, -1.5000e-01,  4.2840e-02, -1.1730e-01, -4.0050e-01,\n",
            "        -2.3397e-01, -7.2866e-01, -3.5928e-01,  4.2980e-01,  2.0247e-01,\n",
            "         4.7775e-02, -1.8988e-01,  1.4026e-01,  4.7262e-01,  2.9465e-01,\n",
            "        -4.6721e-01,  4.3352e-02, -1.1868e-01, -7.1534e-01, -3.5330e-01,\n",
            "         6.3016e-01, -4.8528e-01, -3.8960e-02, -2.2114e-01, -2.4189e-01,\n",
            "        -6.2859e-02, -1.5962e-01, -1.5015e-01,  2.2635e-01, -2.9310e-01,\n",
            "         1.4918e-01, -2.4853e-01,  1.8756e-01, -1.7818e-01,  1.5790e-02,\n",
            "         8.9519e-01, -9.1420e-02,  3.9348e-01,  3.9633e-02,  4.3769e-01,\n",
            "         8.2128e-02, -2.6583e-01,  1.0719e-01,  2.4877e-01,  4.1521e-01,\n",
            "        -3.0047e-01,  1.6897e-01, -1.7872e-01, -1.7884e-01, -3.6050e-02,\n",
            "         6.8345e-02, -3.4804e-01, -9.3207e-02, -3.3487e-02, -1.9079e-01,\n",
            "        -4.7730e-02,  2.1589e-01, -1.7649e-02,  1.0272e-01,  2.2214e-01,\n",
            "         2.4598e-02,  8.8886e-02, -1.9065e-02,  4.7940e-01,  1.7632e-01,\n",
            "         4.2462e-02,  4.0794e-01,  1.7895e-01, -3.6609e-01, -2.2922e-01,\n",
            "         1.1337e-01, -5.0475e-01,  2.0761e-01, -5.2469e-01,  2.5814e-01,\n",
            "         2.0181e-01, -2.5736e-02, -2.3437e-01, -4.9483e-02,  9.1705e-02,\n",
            "        -6.4364e-02,  1.2149e-01, -4.1186e-01,  9.7710e-02, -1.2508e-01,\n",
            "         4.0763e-02, -3.4717e-01,  3.8143e-01,  7.6530e-02, -1.9414e-01,\n",
            "         1.8410e-01, -1.1920e-02, -2.0051e-01,  1.1443e-01,  1.8088e-01,\n",
            "        -1.7253e-01, -1.7402e-01,  1.1461e-01, -2.6830e-01, -9.8872e-02,\n",
            "         3.9775e-02,  1.3449e-01, -1.6283e-01,  2.1166e-03, -7.8610e-02,\n",
            "        -4.6200e-01,  5.7786e-01,  1.1279e-01,  1.9048e-01, -3.5723e-02,\n",
            "         2.1164e-01, -1.4711e-02, -3.3993e-01, -1.2703e-01,  1.0326e-01,\n",
            "         5.0958e-03,  3.7435e-01,  1.7189e-01,  5.8345e-01,  1.6680e-02,\n",
            "        -1.5684e-01,  1.5378e-01,  2.2153e-01, -2.6531e-01,  2.5017e-01,\n",
            "         4.2574e-01, -1.5066e-01,  2.1265e-01,  1.1999e-01, -4.2866e-01,\n",
            "         2.5087e-02,  2.5251e-01,  1.4382e-01,  2.3328e-01,  2.0313e-01,\n",
            "         1.7169e-01,  2.3621e-02,  5.1524e-02, -4.0105e-02, -2.4421e-01,\n",
            "        -3.3788e-01, -2.7906e-01,  8.5631e-02,  3.7364e-01,  3.3528e-01,\n",
            "        -2.2078e-01, -4.9870e-03,  4.2258e-02,  1.6184e-01,  2.2989e-01,\n",
            "         1.0930e-01,  9.5693e-02,  5.9743e-01,  6.8596e-01, -3.4541e-01,\n",
            "        -3.4690e-02, -4.9943e-02, -4.3828e-02, -9.8948e-03, -1.8422e-02,\n",
            "         6.7103e-02, -2.2258e-02, -2.2984e-02, -4.0703e-01,  2.6124e-01,\n",
            "         4.1154e-01, -2.2699e-02, -1.9614e-01, -9.2900e-02, -7.1759e-02,\n",
            "        -1.3627e-01, -2.9177e-01, -9.5445e-03, -2.9971e-01, -2.9886e-02,\n",
            "         4.1862e-01,  5.2153e-02,  6.1977e-02, -1.9548e-01,  1.2748e-01,\n",
            "         1.7454e-02,  2.9819e-01, -1.5988e-01,  1.5838e-02, -8.1305e-02,\n",
            "         1.8233e-02,  7.7923e-02,  1.7629e-01,  1.3150e-01, -1.5991e-01,\n",
            "         2.5084e-01,  2.5934e-01, -2.0483e-01,  3.1098e-02,  3.3086e-01,\n",
            "        -5.5236e-01, -1.7119e-02, -1.7480e-01,  5.3122e-01,  3.7780e-01,\n",
            "         1.3010e-01, -4.2268e-02,  2.4855e-01, -3.1270e-01, -5.0033e-01,\n",
            "         3.0209e-01, -5.2464e-01,  2.9341e-03,  9.4141e-01, -1.9262e-01,\n",
            "         1.2447e-02, -5.6114e-02, -3.5636e-01,  1.8700e-01, -4.5735e-02,\n",
            "         7.4748e-02, -2.0243e-01,  2.5534e-01, -3.2713e-01,  3.1265e-01,\n",
            "        -3.5376e-01, -5.1488e-02,  1.4935e-01, -3.9786e-02,  1.0336e-02,\n",
            "        -5.6745e-01, -8.2600e-02, -2.4669e-01, -1.2936e-01, -2.3212e-01,\n",
            "         7.3379e-02,  4.0745e-01, -1.6200e-01, -7.2630e-02,  1.1524e-01,\n",
            "        -1.4988e-01, -7.2060e-02,  5.8054e-01, -1.8932e-02,  1.1245e-01,\n",
            "         3.2097e-01, -2.5848e-01,  3.1161e-01,  3.9392e-01, -3.5412e-01,\n",
            "        -1.9400e-01, -1.5293e-01, -2.4102e-01, -3.0125e-02,  3.7008e-01,\n",
            "         2.2403e-01,  7.8257e-02, -2.6900e-01, -3.4572e-01, -2.6427e-03,\n",
            "         1.7712e-02, -1.1895e-01,  4.3233e-02, -8.8319e-02,  4.5463e-03,\n",
            "        -2.5439e-01,  1.4728e-01,  4.8581e-01,  4.9114e-02, -1.8314e-01,\n",
            "        -5.9602e-02,  1.2808e-01, -5.5221e-02, -2.2270e-01, -3.5185e-01,\n",
            "         9.6983e-02,  1.9694e-01, -4.9657e-02, -2.3089e-01,  9.6932e-02,\n",
            "        -5.9364e-02, -1.0977e-01, -1.0774e+00, -1.7037e-01, -5.0538e-01,\n",
            "        -1.3686e-01, -4.6037e-01,  1.6326e-01,  5.6601e-01,  6.3966e-02,\n",
            "        -2.1306e-01, -1.4903e-01,  2.7365e-01,  7.4819e-02, -5.1875e-03,\n",
            "        -5.4666e-02,  4.2225e-01, -1.0746e-01,  3.5039e-02, -3.6283e-01,\n",
            "         4.7700e-02, -3.4952e-02,  2.4087e-01, -1.5248e-02, -1.0470e-01,\n",
            "        -2.1243e-01, -5.1084e-01,  3.7812e-02, -2.0369e-01,  8.7615e-03,\n",
            "        -5.5485e-03, -1.4413e-02, -1.5388e-01,  2.1188e-01,  6.3783e-02,\n",
            "         2.0168e-01, -4.1447e-01,  1.8987e-01,  1.7409e-01,  1.5857e-01,\n",
            "         1.0428e-02, -2.3079e-01, -2.0696e-01,  1.5372e-01, -1.3400e-01,\n",
            "        -6.5151e-02, -9.0121e-02,  1.3587e-01, -1.1827e-01, -2.9220e-02,\n",
            "         9.5783e-02,  6.6439e-02, -2.1316e-02, -2.3742e-01, -1.7472e-01,\n",
            "        -7.9916e-01,  4.4483e-02,  2.8404e-01, -2.2308e-02, -5.6764e-02,\n",
            "         1.9825e-01, -2.0278e-01,  3.3376e-01, -5.7932e-02, -2.7878e-01,\n",
            "         4.6812e-01,  2.6236e-01, -9.5878e-02, -1.5614e-01, -1.8900e-01,\n",
            "        -4.5504e-02, -1.4836e-01, -7.0387e-02, -2.5256e-01, -3.6207e-02,\n",
            "        -2.3713e-01,  1.1566e-01, -6.3016e-02, -1.5543e-01, -1.6353e-01,\n",
            "         1.1100e-01, -5.8401e-02, -4.0934e-01, -5.6329e-02, -1.1422e-01,\n",
            "         4.5686e-01,  1.9147e-01, -2.4061e+00, -1.3890e-01,  4.9572e-02,\n",
            "         1.0699e-01,  1.8370e-01, -4.5469e-02, -8.1192e-02, -1.1795e-01,\n",
            "        -1.3250e-01, -3.6430e-02,  2.8795e-01, -7.0326e-02,  9.9012e-02,\n",
            "         7.5754e-02, -8.5289e-02, -2.4367e-02])\n",
            "torch.Size([768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "UUMWB464FfxD"
      },
      "source": [
        "**We now have a vector of 768 features representing our input sentence.** But we can do more! The BERT paper discusses\n",
        "how they reached the best results by concatenating the output of the last four layers.\n",
        "\n",
        "![BERT embeddings visualization](img/bert-feature-extraction-contextualized-embeddings.png)\n",
        "\n",
        "In our example, that means that\n",
        "we need to get the last four layers of `hidden_states` and concatenate them after which we can take the mean. We want\n",
        "to concatenate across the axis of the hidden dimensions of `768`. As a consequence, our concatenated output vector will\n",
        "be of size `(1, 5, 3072)` where `3072=4*768`, i.e. the concatenation of four layers with a hidden dimension of 768. The\n",
        "concatenated vector is much larger than the output of only a single layer, meaning that it contains a lot more features.\n",
        "Do note, as usual, that it depends on your specific task whether these `3072` features perform better than `768`.\n",
        "\n",
        "Having a vector of shape `(1, 5, 3072)`, we still need to take the mean over the token dimension, as we did before. We\n",
        "end up with one feature vector of size `(3072,)`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkiKUPlJFfxD",
        "outputId": "aee32c48-0630-4f64-b051-30d0f1f57663"
      },
      "source": [
        "# get last four layers\n",
        "last_four_layers = [hidden_states[i] for i in (-1, -2, -3, -4)]\n",
        "# cast layers to a tuple and concatenate over the last dimension\n",
        "cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
        "print(cat_hidden_states.size())\n",
        "\n",
        "# take the mean of the concatenated vector over the token dimension\n",
        "cat_sentence_embedding = torch.mean(cat_hidden_states, dim=1).squeeze()\n",
        "print(cat_sentence_embedding)\n",
        "print(cat_sentence_embedding.size())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 5, 3072])\n",
            "tensor([ 0.2750,  0.1831, -0.0887,  ...,  0.2894, -0.0034,  0.0764])\n",
            "torch.Size([3072])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "0asQFzGxFfxD"
      },
      "source": [
        "## Saving and loading results\n",
        "\n",
        "It is likely that you want to use your generated feature vector in another model or task and just save them to your \n",
        "hard drive. You can easily save a tensor with `torch.save` and load it in another script with `torch.load`. Typically,\n",
        "the `.pt` (PyTorch) extension is used. Note that you cannot read the saved file with a text editor. It is a pickled\n",
        "object which allows for efficient (de)compression. If you do want to save your tensors in a readable format, you can\n",
        "convert a tensor to numpy and using something like `np.savetxt('tensor.txt', your_tensor.numpy())`. I do not recommend\n",
        "that approach (I'd stick with `torch.save` or another compression technique) but it is possible.\n",
        "\n",
        "See how we use `.cpu()`? `cpu()` tells PyTorch that we want to move the output tensor back from the GPU to the CPU. \n",
        "This is not a required step, but I think it is good practice when doing feature extraction to move your data to CPU so\n",
        "that when you load it, it is also loaded as a CPU tensor rather than a CUDA tensor. Afterwards you can still move \n",
        "things to GPU if need be, but using CPU by default seems like a good idea. Note that a tensor has to be on CPU if you\n",
        "want to convert it to `.numpy()`, though."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "BuPvifwTFfxE"
      },
      "source": [
        "# save our created sentence representation\n",
        "torch.save(cat_sentence_embedding.cpu(), 'my_sent_embed.pt')\n",
        "\n",
        "# load it again\n",
        "loaded_tensor = torch.load('my_sent_embed.pt')\n",
        "print(loaded_tensor)\n",
        "print(loaded_tensor.size())\n",
        "\n",
        "# convert it to numpy to use in e.g. sklearn\n",
        "np_loaded_tensor = loaded_tensor.numpy()\n",
        "print(np_loaded_tensor)\n",
        "print(type(np_loaded_tensor))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}